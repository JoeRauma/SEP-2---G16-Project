// The pre-defined collection types used in this pseudocode:
// * (T, U, ...) / Tuple
//   * A sequence collection of varying types but with a constant length
//   * Implemented as an array, struct, object, or map, if tuple-types are not available
// * List<T>
//   * A sequence collection with it's elements in order
//   * Implemented as a dynamic array/vector or linked list
// * Stack<T>
//   * A sequence collection which can pop the last inserted item, LIFO
//   * Can be implemented similarly to the `List` type
// * Queue<T>
//   * A sequence collection which can dequeue the first inserted item, FIFO
//   * Can be implemented similarly to the `List` type
// * Set<T>
//   * A collection of data where no two elements are the same
//   * Can in some places be implemented with just a dynamic array/vector
// * Map<K, V>
//   * An associative collection made of pairs
//   * The key values of type `K` can be used to fetch a value of type `V`
//
// All type names will start with a capital letter (ie. Int, Float, Bool)


// Contains uniquely identifying information about a user, e.g. an id-number.
type UserID {
    ...
}


// An interest or hobby of an user.
//
// Implementation details are not important here, other than that you can compare their equality and inequality.
type Interest {
    ...
}


// A group of users formed by the matching algorithm.
type Group {
    Set<UserID> users,
    Interest interest,
    ...  // other relevant data for other parts of the software
}


// The function implementing the group matching algorithm.
//
// Uses a modified Hopcroft-Karp algorithm.
//
// As it's inputs it gets:
// * `min_group_size`, the smallest allowed group size
// * `group_size`, the desired group size
// * `users_to_interests`, a map from users to their interests
// * `interests_to_users`, a map from interests to their users
// *  `old_groups`, the previous list of formed groups
//
// The maximum group size will be `group_size + min_group_size - 1`.
//
// This returns the new list of formed groups, which doesn't contain repeats from the old list.
//
// The function works in these steps:
// 1. Allot Group Slots
//     * Allot each Interest their "group slots" (how many people will form groups based on that interest)
// 2. Create Initial Matching
//     * Create the first crude matching
// 3. Hopcroft-Karp
//     * Use Hopcroft-Karp to iteratively get better matchings
// 4. Form Groups
//     * Create the groups from the matching
// 5. Insert Small Groups
//     * Add groups that were larger or equal to `min_group_size`
//     * Append groups that were smaller than `min_group_size` to the existing groups

Set<Group> form_groups(
        Int min_group_size,
        Int group_size,
        Map<UserID, Set<Interest>> users_to_interests,
        Map<Interest, Set<UserID>> interests_to_users,
        Set<Group> old_groups,
    )
{
    // ---
    // STEP 1: ALLOT GROUP SLOTS
    // ---

    // Allot group spots for each interest
    Map<Interest, Int> free_spots = calculate_group_spots(
        min_group_size,
        group_size,
        users_to_interests.len(),
        interests_to_users
    )

    // ---
    // STEP 2: CREATE INITIAL MATCHING
    // ---

    // The matchings between users and interests used in the algorithm
    Map<UserID, Interest> matchings;
    Map<Interest, Set<UserID>> matchings_inverse;

    // Get the initial matchings
    // The order that the users are iterated and the interests are picked should be random to avoid bias
    for (user, interests) in users_to_interests {
        for interest in interests {
            if free_spots[interest] > 0 {
                matchings[user] = interests
                matchings_inverse[interest].insert(user)
                free_spots[interest] -= 1
            }
        }
    }

    // ---
    // STEP 3: HOPCROFT-KARP
    // ---

    // Run the algorithm until the maximal matching has been found
    while(
        hopcroft_karp(
            users_to_interests,
            interests_to_users,
            &free_spots,
            &matchings,
            &matchings_inverse,
        ) > 0
    )
    {}

    // ---
    // STEP 4: FORM GROUPS
    // ---

    // TODO: Make a better group forming by using `matchings_inverse` in place of `matchings`

    // The final resulting list of groups
    Set<Group> groups

    // A helper map for WIP groups
    Map<Interest, Group> unfinished_groups
    for interest in interests_to_users.keys() {
        unfinished_groups[interest] = new Group(users = [], interest = interest)
    }

    // Form the groups
    // TODO: Check for repeats of old groups and replace them
    for (user, interest) in matchings {
        Group g = unfinished_groups[interest]
        g.users.insert(user)

        if g.users.len() >= group_size {
            // Finish a group
            groups.insert(g)
            unfinished_groups[interest] = new Group(users = [], interest = interest)
        } else {
            unfinished_groups[interest] = g  // not needed if you were using a reference and not a clone of the original
        }
    }

    // ---
    // STEP 5: INSERT SMALL GROUPS
    // ---

    // Add the groups that were small
    // If they were too small, they're appended to an existing group
    for small_group in unfinished_groups.values() {
        if small_group.len() >= min_group_size {
            groups.insert(small_group)
        } else {
            // append to an existing good group
            for ok_group in groups {
                if ok_group.interest = small_group.interest {
                    ok_group.users.append(small_group.users)
                }
            }
        }
    }

    return groups
}


// Calculates how many group spots each interest should have.
//
// The total amount of spots will be exactly the same as `number_of_users`.
//
// Most of the spots allocated for each interest should be divisible by `group_size`,
// but their remainder should never be smaller than `min_group_size`.
// (This is to make sure that most groups will be of the desired size while no group will be too small)

Map<Interest, Int> calculate_group_spots(
        Int min_group_size,
        Int group_size,
        Int number_of_users,
        Map<Interest, Set<UserID>> interests_to_users,
    )
{
    // Count how many users does each interest have and count the sum of those values
    Map<Interest, Int> spots_per_interest
    Int count_total = 0
    for (interest, users) in interests_to_users {
        spots_per_interest[interest] = users.len()
        count_total += users.len()
    }

    Int free_spots = number_of_users

    // Transform the amounts of people in each interest from raw counts into weight values and then to spot counts
    for (interest, count) in spots_per_interest {
        Int spots = floor(count / count_total * number_of_users)  // be sure to do the calculation in floating points
        free_spots -= spots
        spots_per_interest[interest] = spots
    }

    // TODO: Spread any remaining free spots with the interests and try to make as many of the spots for each interests
    // to be divisible by the `group_size` while making sure that all of their remainders will be greater or equal to
    // `min_group_size`.

    return spots_per_interest
}


// A modified Hopcroft-Karp algorithm.
//
// Gets references to the free spots, current matchings, and it's inverse, which this function will mutate.
//
// Returns the amount of matchings made.
// 0 means that the maximal matching was reached and the algorithm has finished.

Int hopcroft_karp(
        Map<UserID, Set<Interest>> users_to_interests,
        Map<Interest, Set<UserID>> interests_to_users,
        &Map<Interest, Int> free_spots,
        &Map<UserID, Interest> matchings,
        &Map<Interest, Set<UserID>> matchings_inverse,
    )
{
    // check if there's no spots left anymore
    if all values in free_spots >= 0 {
        return 0
    }

    Int new_matchings = 0

    // Find unmatched user vertices
    // (unmatched interest vertices are in `free_spots`)
    Set<UserID> unmatched_users
    for (user, _interests) in users_to_interests {
        if not matchings.has_key(user) {
            unmatched_users.insert(user)
        }
    }

    // Users to be searched by the BFS
    Queue<UserID> bfs_queue = unmatched_users
    // Users already found by the BFS
    Set<UserID> users_visited_bfs = unmatched_users
    // Users removed due to them being in an augmenting path
    Set<UserID> removed_users

    // The resulting list of augmenting paths
    Set<List<(User, Interest)>> augmenting_paths

    // Create alternating level graph with a breadth-first-search
    while bfs_queue is not empty {
        UserID bfs_user = bfs_queue.dequeue()

        // Try to eagerly find any free spots
        Bool found_spot = false
        for interest in users_to_interests[bfs_user] {
            if free_spots[interest] > 0 {
                // Found a free spot, which is a possible endpoint of an augmenting path

                // Users visited by the DFS
                Set<UserID> users_visited_dfs

                // Try to find an augmenting path with a depth-first-search
                List<(Interest, User)> path = dfs_augmenting_path(
                    users_to_interests,
                    interests_to_users,
                    unmatched_users,
                    users_visited_bfs.exclude(removed_users),
                    interest,
                    &users_visited_dfs,
                )

                if path is not empty {
                    augmenting_paths.insert(path)

                    for (_interest, user) in path {
                        // Remove the users in the path from the future dfs searches
                        removed_users.insert(user)
                    }
                }

                found_spot = true
            }
        }

        if not found_spot {
            // Continue the search
            for interest in users_to_interests[bfs_user] {
                Set<UserID> to_search = interests_to_users[bfs_user].exclude(users_visited_bfs)
                bfs_queue.append(to_search)
                users_visited_bfs.append(to_search)
            }
        }
    }

    // TODO: augment the graph with the augmenting paths

    return new_matchings
}

// Uses a depth-first-search to find an augmenting path from the given interest.
//
// It's inputs are:
// * users_to_interests, interests_to_users
//   * The user-interest graph
// * unmatched_users
//   * Users without matched, the potential endpoints of the path
// * domain
//   * The sub-graph domain that the search will operate on
// * search_start
//   * The start node of the DFS search
//   * The endpoint of the graph in the Interest nodes
// * users_visited
//   * A reference to a set of all users visited by this search
//   * For internal purposes
//   * Will be mutated

List<(Interest, UserID)> dfs_augmenting_path(
        Map<UserID, Set<Interest>> users_to_interests,
        Map<Interest, Set<UserID>> interests_to_users,
        Set<UserID> unmatched_users,
        Set<UserID> domain,
        Interest search_start,
        &Set<UserID> users_visited,
    )
{
    users_visited.insert(search_start)

    // Eagerly check if we found the other endpoint of the augmenting path
    for user in interests_to_users[search_start] {
        if user is in unmatched_users {
            return [(search_start, user)]
        }
    }

    // Continue the search
    for user in interests_to_users[search_start].intersect(domain).exclude(users_visited) {
        for interest in users_to_interests[user] {
            // Recursively search for the path
            List<(Interest, UserID)> path = dfs_augmenting_path(
                users_to_interests,
                interests_to_users,
                unmatched_users,
                domain,
                interest,
                &users_visited
            )

            if path is not empty {
                // Construct the output path
                return [(search_start, user)].append(path)
            } else {
                // No path was found
                return []
            }
        }
    }

    // Reached a dead end, no path was found
    return []
}
